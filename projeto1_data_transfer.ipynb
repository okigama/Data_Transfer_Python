{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Código Transfer Learning com python"
      ],
      "metadata": {
        "id": "lk4LYKt2d5r4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1eLgBNTGeoTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# IMPORTAR O DATASET PELO DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rK9XIVsBZ9Fi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5b021c-a3a7-48ff-c4dd-2851dfc2b7e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 Carregar o MobileNetV2"
      ],
      "metadata": {
        "id": "tpUf-siuaPDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape = (128, 128, 3))\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "Lx7QPJA8aaPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32010117-a855-440f-8a21-49a140326a83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Adicionar as novas camadas"
      ],
      "metadata": {
        "id": "Lc-qSQg2aulE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='sigmoid'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0fowwypPa1Xc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Preparar as imagens"
      ],
      "metadata": {
        "id": "hx-ZtZ5wbV3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1.0 / 255, validation_split=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Meu_Dataset/train',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Meu_Dataset/validation',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqi0migKcw4Z",
        "outputId": "a83747d6-91bb-4353-d281-858295f13d2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 images belonging to 2 classes.\n",
            "Found 8 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "08fJSqtvaKjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 Treinar o modelo"
      ],
      "metadata": {
        "id": "njeG5sLOdP_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "gQUo0UZMdqOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09a1368-882e-4209-a56e-67fda9f18d89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7s/step - accuracy: 0.8948 - loss: 0.4139 - val_accuracy: 0.5000 - val_loss: 1.0608\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8556 - loss: 0.3443 - val_accuracy: 0.5000 - val_loss: 1.2468\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7730 - loss: 0.2814 - val_accuracy: 0.5000 - val_loss: 0.9940\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8790 - loss: 0.1863 - val_accuracy: 0.5000 - val_loss: 0.6885\n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step - accuracy: 0.9508 - loss: 0.1119 - val_accuracy: 0.7500 - val_loss: 0.4527\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0648 - val_accuracy: 0.7500 - val_loss: 0.3282\n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0437 - val_accuracy: 0.8750 - val_loss: 0.2694\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.2372\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0421 - val_accuracy: 1.0000 - val_loss: 0.2153\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0513 - val_accuracy: 1.0000 - val_loss: 0.1968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 Avaliar o modelo"
      ],
      "metadata": {
        "id": "O6GWgcnfduRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "sImTRzd3dyMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc28d67-2923-4ae3-8c89-336bf625747a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1968\n",
            "Loss: 0.19683955609798431, Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}